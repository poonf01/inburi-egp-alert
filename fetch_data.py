import os
import json
import time
import subprocess
import urllib.parse
import requests
from typing import Any, Dict, List, Optional, Tuple

# ======================
# ENV
# ======================
LINE_TOKEN = os.environ.get("LINE_TOKEN", "").strip()
API_KEY = os.environ.get("DATA_API_KEY", "").strip()
RESOURCE_ID = os.environ.get("DATA_RESOURCE_ID", "").strip()

# (‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å) ‡∏ñ‡πâ‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ proxy ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡∏≠‡∏∑‡πà‡∏ô (Render/Railway/VPS)
PROXY_URL = os.environ.get("PROXY_URL", "").strip().rstrip("/")

# ======================
# CONSTANTS
# ======================
OPEND_DATASTORE_SQL = "https://opend.data.go.th/get-ckan/datastore_search_sql"
OPEND_DATASTORE_SEARCH = "https://opend.data.go.th/get-ckan/datastore_search"

LINE_BROADCAST_URL = "https://api.line.me/v2/bot/message/broadcast"
DATA_JSON_PATH = "data.json"

# ======================
# HEADERS (‡∏Å‡∏±‡∏ô WAF ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡πá‡∏°)
# ======================
# NOTE: ‡πÉ‡∏™‡πà‡∏ó‡∏±‡πâ‡∏á api-key ‡πÅ‡∏•‡∏∞ x-api-key ‡πÄ‡∏ú‡∏∑‡πà‡∏≠ gateway ‡∏ö‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏ô‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠
HEADERS_API = {
    "api-key": API_KEY,
    "x-api-key": API_KEY,
    "Accept": "application/json,text/plain,*/*",
    "Accept-Language": "th-TH,th;q=0.9,en-US;q=0.8,en;q=0.7",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
    "Connection": "keep-alive",
    # UA ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô Chrome ‡∏à‡∏£‡∏¥‡∏á (‡∏´‡∏•‡∏≤‡∏¢ WAF ‡∏ö‡∏•‡πá‡∏≠‡∏Å UA ‡∏™‡∏±‡πâ‡∏ô ‡πÜ)
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/122.0.0.0 Safari/537.36"
    ),
    "Referer": "https://data.go.th/",
    "Origin": "https://data.go.th",
}

HEADERS_LINE = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {LINE_TOKEN}",
    "Accept": "application/json",
    "User-Agent": "Mozilla/5.0",
}

# ======================
# HELPERS
# ======================
def require_env() -> bool:
    missing = []
    if not API_KEY:
        missing.append("DATA_API_KEY")
    if not LINE_TOKEN:
        missing.append("LINE_TOKEN")
    if not RESOURCE_ID:
        missing.append("DATA_RESOURCE_ID")

    if missing:
        print("‚ùå Missing environment variables:", ", ".join(missing))
        print("üëâ GitHub Repo > Settings > Secrets and variables > Actions")
        print("   ‡πÄ‡∏û‡∏¥‡πà‡∏° Secrets ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö: LINE_TOKEN, DATA_API_KEY, DATA_RESOURCE_ID")
        return False
    return True


def _short(text: str, n: int = 250) -> str:
    t = (text or "").replace("\n", " ").replace("\r", " ").strip()
    return t[:n]


def _build_url(url: str, params: Dict[str, Any]) -> str:
    q = urllib.parse.urlencode({k: v for k, v in params.items() if v is not None})
    return f"{url}?{q}" if q else url


def _curl_get_json(url: str, headers: Dict[str, str], params: Dict[str, Any], timeout: int = 60) -> Dict[str, Any]:
    full_url = _build_url(url, params)

    cmd = [
        "curl",
        "-sS",
        "-L",
        "--compressed",
        "--connect-timeout",
        str(timeout),
        "--max-time",
        str(timeout),
        full_url,
    ]
    for k, v in headers.items():
        if v:
            cmd.insert(-1, f"{k}: {v}")
            cmd.insert(-1, "-H")

    p = subprocess.run(cmd, capture_output=True, text=True)
    if p.returncode != 0:
        raise RuntimeError(f"curl failed rc={p.returncode}: {_short(p.stderr)}")

    try:
        return json.loads(p.stdout)
    except Exception:
        raise RuntimeError(f"curl returned non-json: {_short(p.stdout)}")


def _requests_get_json(
    url: str,
    headers: Dict[str, str],
    params: Dict[str, Any],
    retries: int = 4,
    timeout: int = 45,
) -> Dict[str, Any]:
    """
    requests ‡∏Å‡πà‡∏≠‡∏ô -> ‡∏ñ‡πâ‡∏≤‡πÇ‡∏î‡∏ô 403/429/5xx ‡∏à‡∏∞ retry ‡πÅ‡∏•‡∏∞‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ throw error ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏£‡∏¥‡∏á
    """
    session = requests.Session()
    last_err: Optional[Exception] = None

    for i in range(retries):
        try:
            resp = session.get(url, headers=headers, params=params, timeout=timeout)

            # OK
            if resp.status_code < 400:
                return resp.json()

            body = _short(resp.text)
            # 403: ‡∏°‡∏±‡∏Å‡πÇ‡∏î‡∏ô WAF ‡∏ö‡∏•‡πá‡∏≠‡∏Å -> ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å retry ‡∏Å‡πá‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á 1-2 ‡∏£‡∏≠‡∏ö‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            if resp.status_code in (403, 429, 500, 502, 503, 504):
                last_err = RuntimeError(f"HTTP {resp.status_code}: {body}")
                wait = 2 ** i
                print(f"‚ö†Ô∏è HTTP {resp.status_code} retry in {wait}s ... ({body})")
                time.sleep(wait)
                continue

            resp.raise_for_status()
            return resp.json()

        except Exception as e:
            last_err = e
            wait = 2 ** i
            print(f"‚ö†Ô∏è Request error retry in {wait}s ... ({e})")
            time.sleep(wait)

    raise RuntimeError(f"requests failed after retries: {last_err}")


def get_json_with_fallback(url: str, headers: Dict[str, str], params: Dict[str, Any]) -> Dict[str, Any]:
    """
    1) requests (‡∏°‡∏µ retry)
    2) ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡∏û‡∏±‡∏á -> curl (‡∏°‡∏±‡∏Å‡∏ú‡πà‡∏≤‡∏ô WAF ‡πÑ‡∏î‡πâ)
    """
    try:
        return _requests_get_json(url, headers, params)
    except Exception as e1:
        print(f"‚ö†Ô∏è requests failed -> trying curl fallback ... ({e1})")

    # curl fallback (‡πÑ‡∏°‡πà retry ‡∏¢‡∏≤‡∏ß ‡πÜ ‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏ß‡∏•‡∏≤)
    return _curl_get_json(url, headers, params, timeout=70)


def load_old_data(path: str = DATA_JSON_PATH) -> List[Dict[str, Any]]:
    if not os.path.exists(path):
        return []
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            return data if isinstance(data, list) else []
    except Exception:
        return []


def save_data(items: List[Dict[str, Any]], path: str = DATA_JSON_PATH) -> None:
    with open(path, "w", encoding="utf-8") as f:
        json.dump(items, f, ensure_ascii=False, indent=2)


def send_line_notify(project_name: str, budget: str, department: str) -> None:
    if not LINE_TOKEN:
        return

    message = (
        "üì¢ ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏à‡∏±‡∏î‡∏ã‡∏∑‡πâ‡∏≠‡∏à‡∏±‡∏î‡∏à‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà!\n\n"
        f"üè¢ ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô: {department}\n"
        f"üìå ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£: {project_name}\n"
        f"üí∞ ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì: {budget} ‡∏ö‡∏≤‡∏ó\n\n"
        "(by Alieninburi)"
    )

    payload = {"messages": [{"type": "text", "text": message}]}

    try:
        resp = requests.post(
            LINE_BROADCAST_URL,
            headers=HEADERS_LINE,
            json=payload,
            timeout=30,
        )
        if resp.status_code >= 400:
            print(f"‚ö†Ô∏è LINE notify failed: HTTP {resp.status_code} {_short(resp.text)}")
    except Exception as e:
        print(f"‚ö†Ô∏è LINE notify exception: {e}")


# ======================
# FETCH
# ======================
def fetch_records_sql(resource_id: str) -> List[Dict[str, Any]]:
    sql = f"""
    SELECT *
    FROM "{resource_id}"
    WHERE project_name LIKE '%‡∏≠‡∏¥‡∏ô‡∏ó‡∏£‡πå‡∏ö‡∏∏‡∏£‡∏µ%'
       OR prov_name LIKE '%‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ%'
       OR dept_name LIKE '%‡∏≠‡∏¥‡∏ô‡∏ó‡∏£‡πå‡∏ö‡∏∏‡∏£‡∏µ%'
    LIMIT 200
    """
    data = get_json_with_fallback(OPEND_DATASTORE_SQL, headers=HEADERS_API, params={"sql": sql})
    return data.get("result", {}).get("records", []) or []


def fetch_records_search(resource_id: str) -> List[Dict[str, Any]]:
    """
    fallback ‡∏≠‡∏µ‡∏Å‡∏ä‡∏±‡πâ‡∏ô: datastore_search (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ SQL)
    ‡∏ó‡∏≥ 2 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏•‡πâ‡∏ß union ‡∏Å‡∏±‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ AND/OR ‡πÉ‡∏ô q
    """
    out: List[Dict[str, Any]] = []
    seen: set = set()

    for q in ["‡∏≠‡∏¥‡∏ô‡∏ó‡∏£‡πå‡∏ö‡∏∏‡∏£‡∏µ", "‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ"]:
        data = get_json_with_fallback(
            OPEND_DATASTORE_SEARCH,
            headers=HEADERS_API,
            params={"resource_id": resource_id, "q": q, "limit": 200},
        )
        recs = data.get("result", {}).get("records", []) or []
        for r in recs:
            pid = str(r.get("project_id", "")).strip()
            key = pid if pid else json.dumps(r, ensure_ascii=False, sort_keys=True)
            if key not in seen:
                seen.add(key)
                out.append(r)

    return out


def fetch_records_via_proxy() -> List[Dict[str, Any]]:
    """
    ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ PROXY_URL ‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ ‡πÄ‡∏ä‡πà‡∏ô https://xxx.onrender.com
    endpoint: /egp -> ‡∏Ñ‡∏∑‡∏ô JSON ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö CKAN
    """
    if not PROXY_URL:
        return []

    url = f"{PROXY_URL}/egp"
    print(f"üåê Using PROXY_URL: {url}")

    # proxy ‡πÄ‡∏£‡∏≤‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á api-key ‡∏Å‡πá‡πÑ‡∏î‡πâ (‡πÄ‡∏û‡∏£‡∏≤‡∏∞ proxy ‡πÄ‡∏Å‡πá‡∏ö key ‡πÄ‡∏≠‡∏á)
    try:
        data = get_json_with_fallback(url, headers={"Accept": "application/json"}, params={})
        return data.get("result", {}).get("records", []) or []
    except Exception as e:
        print(f"‚ö†Ô∏è proxy fetch failed: {e}")
        return []


def fetch_records_any(resource_id: str) -> List[Dict[str, Any]]:
    # 1) SQL ‡∏Å‡πà‡∏≠‡∏ô (‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
    try:
        return fetch_records_sql(resource_id)
    except Exception as e:
        print(f"‚ö†Ô∏è SQL failed: {e}")

    # 2) datastore_search
    try:
        return fetch_records_search(resource_id)
    except Exception as e:
        print(f"‚ö†Ô∏è datastore_search failed: {e}")

    # 3) proxy (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    recs = fetch_records_via_proxy()
    if recs:
        return recs

    # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏≤ ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤‡πÇ‡∏î‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏µ‡∏¢‡πå‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÜ
    raise RuntimeError("All fetch methods failed (SQL, datastore_search, proxy).")


# ======================
# MAIN
# ======================
def main() -> None:
    if not require_env():
        return

    print("‚úÖ Environment OK")
    print("üì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å opend.data.go.th ...")

    try:
        records = fetch_records_any(RESOURCE_ID)
        print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(records)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    except Exception as e:
        print(f"‚ùå ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")
        return

    old_data = load_old_data(DATA_JSON_PATH)
    old_ids = {str(x.get("project_id")) for x in old_data if isinstance(x, dict)}

    new_projects: List[Dict[str, Any]] = []
    for proj in records:
        proj_id = str(proj.get("project_id", "")).strip()
        if not proj_id:
            continue
        if proj_id not in old_ids:
            new_projects.append(proj)

    if new_projects:
        print(f"üÜï ‡∏û‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà {len(new_projects)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô ...")
        for proj in new_projects:
            send_line_notify(
                str(proj.get("project_name", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£")),
                str(proj.get("sum_price_agree", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")),
                str(proj.get("dept_name", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô")),
            )
            print(f"üì® ‡πÅ‡∏à‡πâ‡∏á‡πÅ‡∏•‡πâ‡∏ß: {proj.get('project_name')}")

        save_data(new_projects + old_data, DATA_JSON_PATH)
        print("‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï data.json ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
    else:
        if not os.path.exists(DATA_JSON_PATH):
            save_data([], DATA_JSON_PATH)
        print("üò¥ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà‡∏Ç‡∏≠‡∏á‡∏≠‡∏¥‡∏ô‡∏ó‡∏£‡πå‡∏ö‡∏∏‡∏£‡∏µ")


if __name__ == "__main__":
    main()
